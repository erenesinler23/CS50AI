# Analysis

## Layer 3, Head 10

In this section, we analyze the attention head in Layer 3, Head 10 of the BERT model.
This attention head appears to capture the syntactic relationship between nouns and verbs.

### Observation
The attention head in Layer 3, Head 10 consistently focuses on the connection between the subject and the corresponding verb in a sentence. 
It seems to be adept at identifying the core syntactic structure.

** For the first example sentence, it said "glided", "moved" and "walked".
** For the second example sentence, it said "watch", "attend" and "watched".

Example Sentences:
- The cat [MASK] gracefully across the rooftop.
- A group of students [MASK] the fascinating lecture.


## Layer 4, Head 11

Next, we examine the attention head in Layer 4, Head 11 of the BERT model. ,
This attention head seems to focus on capturing the semantic relationship between adjectives and nouns.

### Observation
The attention head in Layer 4, Head 11 consistently attends to the adjectives modifying nouns in a sentence. 
It appears to be sensitive to the nuances of descriptive language.

** For the firt example sentence, it said "morning", "setting" and "afternoon". 
** For the second example sentence, it said "black", "white" and "red". 

Example Sentences:
- The [MASK] sun set behind the mountains.
- She wore a beautiful [MASK] dress to the party.

